https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/
https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards/
https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/
https://openai.com/index/prover-verifier-games-improve-legibility/
https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world/
https://openai.com/index/improved-techniques-for-training-consistency-models/
https://openai.com/index/consistency-models/
https://openai.com/index/extracting-concepts-from-gpt-4/
https://openai.com/index/hello-gpt-4o/
https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online/
https://openai.com/index/the-instruction-hierarchy/
https://openai.com/index/video-generation-models-as-world-simulators/
https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation/
https://openai.com/index/improving-mathematical-reasoning-with-process-supervision/
https://www.anthropic.com/news/mapping-mind-language-model
https://transformer-circuits.pub/2024/july-update/index.html
https://transformer-circuits.pub/2024/june-update/index.html
https://www.anthropic.com/research/reward-tampering
https://www.anthropic.com/research/engineering-challenges-interpretability
https://www.anthropic.com/research/claude-character
https://www.anthropic.com/news/testing-and-mitigating-elections-related-risks
https://www.anthropic.com/research/mapping-mind-language-model
https://www.anthropic.com/research/circuits-updates-april-2024
https://www.anthropic.com/research/probes-catch-sleeper-agents
https://www.anthropic.com/research/measuring-model-persuasiveness
https://www.anthropic.com/research/many-shot-jailbreaking
https://www.anthropic.com/research/transformer-circuits
https://www.anthropic.com/research/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training
https://www.anthropic.com/research/evaluating-and-mitigating-discrimination-in-language-model-decisions
https://www.anthropic.com/research/specific-versus-general-principles-for-constitutional-ai
https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models
https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input
https://www.anthropic.com/research/decomposing-language-models-into-understandable-components
https://www.anthropic.com/research/towards-monosemanticity-decomposing-language-models-with-dictionary-learning
https://www.anthropic.com/research/evaluating-ai-systems
https://www.anthropic.com/research/influence-functions
https://www.anthropic.com/research/studying-large-language-model-generalization-with-influence-functions
https://www.anthropic.com/research/measuring-faithfulness-in-chain-of-thought-reasoning
https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/