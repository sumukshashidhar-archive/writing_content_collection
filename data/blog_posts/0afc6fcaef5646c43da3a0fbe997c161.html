Title: A Holistic Approach to Undesired Content Detection in the Real World

URL Source: https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world/

Markdown Content:
A Holistic Approach to Undesired Content Detection in the Real World | OpenAI
===============

[Skip to main content](https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world/#main)

[](https://openai.com/)

*   Research
*   Products
*   Safety
*   Company

June 20, 2024

A Holistic Approach to Undesired Content Detection in the Real World
====================================================================

[Read paper(opens in a new window)](https://arxiv.org/abs/2208.03274)

![Image 1: An abstract painting with shades of blue, beige, and green, featuring geometric shapes and curved lines, creating a calm and balanced composition.](https://images.ctfassets.net/kftzwdyauwt9/45vht2Rly5yzF0bP6ragTn/cca3a22e662dc1472f15dc008095b6b6/A_Holistic_Approach_to_Undesired_Content_Detection_in_the_Real_World.jpg?w=3840&q=90&fm=webp)

We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation. The success of such a system relies on a chain of carefully designed and executed steps, including the design of content taxonomies and labeling instructions, data quality control, an active learning pipeline to capture rare events, and a variety of methods to make the model robust and to avoid overfitting. Our moderation system is trained to detect a broad set of categories of undesired content, including sexual content, hateful content, violence, self-harm, and harassment. This approach generalizes to a wide range of different content taxonomies and can be used to create high-quality content classifiers that outperform off-the-shelf models.

Authors
-------

[Todor Markov](https://openai.com/news/?author=todor-markov#results), [Chong Zhang](https://openai.com/news/?author=chong-zhang#results), [Sandhini Agarwal](https://openai.com/news/?author=sandhini-agarwal#results), [Tyna Eloundou](https://openai.com/news/?author=tyna-eloundou#results), [Teddy Lee](https://openai.com/news/?author=teddy-lee#results), [Steven Adler](https://openai.com/news/?author=steven-adler#results), [Angela Jiang](https://openai.com/news/?author=angela-jiang#results), [Lilian Weng](https://openai.com/news/?author=lilian-weng#results)

Our research

*   [Overview](https://openai.com/research/)
*   [Index](https://openai.com/news/research/)

Latest advancements

*   [GPT-4](https://openai.com/index/gpt-4/)
*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
*   [DALL·E 3](https://openai.com/index/dall-e-3/)
*   [Sora](https://openai.com/index/sora/)

ChatGPT

*   [For Everyone](https://openai.com/chatgpt/)
*   [For Teams](https://openai.com/chatgpt/team/)
*   [For Enterprises](https://openai.com/chatgpt/enterprise/)
*   [ChatGPT login(opens in a new window)](https://chatgpt.com/)
*   [Download](https://openai.com/chatgpt/download/)

API

*   [Platform overview](https://openai.com/api/)
*   [Pricing](https://openai.com/api/pricing/)
*   [Documentation(opens in a new window)](https://platform.openai.com/docs/introduction)
*   [API login(opens in a new window)](https://platform.openai.com/login?launch)

Explore more

*   [OpenAI for business](https://openai.com/business/)
*   [Stories](https://openai.com/news/stories/)

Safety overview

*   [Safety overview](https://openai.com/safety/)
*   [Safety standards](https://openai.com/safety-standards/)

Teams

*   [Safety Systems](https://openai.com/safety-systems/)
*   [Preparedness](https://openai.com/preparedness/)
*   [Superalignment](https://openai.com/superalignment/)

Company

*   [About us](https://openai.com/about/)
*   [News](https://openai.com/news/)
*   [Our Charter](https://openai.com/charter/)
*   [Security](https://openai.com/security-and-privacy/)
*   [Residency](https://openai.com/residency/)
*   [Careers](https://openai.com/careers/)

Terms & policies

*   [Terms of use](https://openai.com/policies/terms-of-use/)
*   [Privacy policy](https://openai.com/policies/privacy-policy/)
*   [Brand guidelines](https://openai.com/brand/)
*   [Other policies](https://openai.com/policies/)

OpenAI © 2015–2024

[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/?hl=en)[(opens in a new window)](https://www.tiktok.com/@openai?lang=en)[(opens in a new window)](https://discord.gg/openai)
